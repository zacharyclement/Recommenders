{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e33808-4b51-4ba6-980a-ea13741757bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold# Baseline\n",
    "\n",
    "\n",
    "\n",
    "reader = surprise.Reader(rating_scale=(0, 1))\n",
    "data = surprise.Dataset.load_from_df(\n",
    "    df[[\"user_id\", \"content_id\", \"engaged_pct\"]], reader\n",
    ")\n",
    "\n",
    "from surprise import Dataset, accuracy\n",
    "from surprise.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "## Baselines\n",
    "\n",
    "#%%timeit\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "\n",
    "algorithms = [\n",
    "    surprise.SVDpp(),  # works\n",
    "    surprise.SVD(),  # wors\n",
    "    surprise.SlopeOne(),  # works\n",
    "    surprise.NormalPredictor(),  # works\n",
    "    surprise.KNNBaseline(),  # works\n",
    "    surprise.KNNBasic(),  # works\n",
    "    surprise.KNNWithMeans(),\n",
    "    surprise.KNNWithZScore(),\n",
    "    surprise.BaselineOnly(),\n",
    "    surprise.CoClustering(),\n",
    "    # surprise.NMF(),  # division by 0 error\n",
    "]\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    # Perform cross validation\n",
    "    results = surprise.model_selection.cross_validate(\n",
    "        algorithm,\n",
    "        data,\n",
    "        measures=[\"RMSE\", \"MAE\"],\n",
    "        cv=3,\n",
    "        verbose=False,  # root mean squared error (RMSE), mean absolute error (MAE)\n",
    "    )\n",
    "\n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "\n",
    "    tmp = tmp.append(\n",
    "        pd.Series([str(algorithm).split(\" \")[0].split(\".\")[-1]], index=[\"Algorithm\"])\n",
    "    )\n",
    "    benchmark.append(tmp)\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark).set_index(\"Algorithm\").sort_values(\"test_rmse\")\n",
    "benchmark_df\n",
    "\n",
    "# how to interprest RMSE and MAE\n",
    "\n",
    "# common sparsity measure\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "# algo = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "\n",
    "print(\"Using ALS?\")\n",
    "param_grid = {\"n_epochs\": [5, 10], \"lr_all\": [0.002, 0.005], \"reg_all\": [0.4, 0.6]}\n",
    "gs = GridSearchCV(surprise.SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "fit_gs = gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "best_score = gs.best_score[\"rmse\"]\n",
    "best_params = gs.best_params[\"rmse\"]\n",
    "best_estimator = gs.best_estimator[\"rmse\"]\n",
    "\n",
    "print(\"best score: \", best_score)\n",
    "print(\"best params: \", best_params)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df\n",
    "\n",
    "## Get Best Params\n",
    "# Make PRedications\n",
    "\n",
    "predictions = best_estimator.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "best_estimator.fit(data.build_full_trainset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
